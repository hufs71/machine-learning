{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/HAR_dataset/features.txt'\n",
    "\n",
    "feature_name_df = pd.read_csv(url, sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
    "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
    "\n",
    "X_train_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/HAR_dataset/train/X_train.txt'\n",
    "X_test_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/HAR_dataset/test/X_test.txt'\n",
    "\n",
    "X_train = pd.read_csv(X_train_url, sep='\\s+', header=None)\n",
    "X_test = pd.read_csv(X_test_url, sep='\\s+', header=None)\n",
    "\n",
    "X_train.columns = feature_name\n",
    "X_test.columns = feature_name\n",
    "\n",
    "y_train_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/HAR_dataset/train/y_train.txt'\n",
    "y_test_url = 'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/HAR_dataset/test/y_test.txt'\n",
    "\n",
    "y_train = pd.read_csv(y_train_url, sep='\\s+', header=None, names=['action'])\n",
    "y_test = pd.read_csv(y_test_url, sep='\\s+', header=None, names=['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jhpark/Documents/ds_study/machine_learning/11. GBM, XGBoost, LGBM.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gb_clf \u001b[39m=\u001b[39m GradientBoostingClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m gb_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m gb_pred \u001b[39m=\u001b[39m gb_clf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:525\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    524\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[1;32m    526\u001b[0m     X,\n\u001b[1;32m    527\u001b[0m     y,\n\u001b[1;32m    528\u001b[0m     raw_predictions,\n\u001b[1;32m    529\u001b[0m     sample_weight,\n\u001b[1;32m    530\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[1;32m    531\u001b[0m     X_val,\n\u001b[1;32m    532\u001b[0m     y_val,\n\u001b[1;32m    533\u001b[0m     sample_weight_val,\n\u001b[1;32m    534\u001b[0m     begin_at_stage,\n\u001b[1;32m    535\u001b[0m     monitor,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    538\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:603\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    596\u001b[0m         initial_loss \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    597\u001b[0m             y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    598\u001b[0m             raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    599\u001b[0m             sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    600\u001b[0m         )\n\u001b[1;32m    602\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[1;32m    604\u001b[0m     i,\n\u001b[1;32m    605\u001b[0m     X,\n\u001b[1;32m    606\u001b[0m     y,\n\u001b[1;32m    607\u001b[0m     raw_predictions,\n\u001b[1;32m    608\u001b[0m     sample_weight,\n\u001b[1;32m    609\u001b[0m     sample_mask,\n\u001b[1;32m    610\u001b[0m     random_state,\n\u001b[1;32m    611\u001b[0m     X_csc,\n\u001b[1;32m    612\u001b[0m     X_csr,\n\u001b[1;32m    613\u001b[0m )\n\u001b[1;32m    615\u001b[0m \u001b[39m# track loss\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    242\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    244\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 245\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    247\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    248\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    249\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    250\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    258\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=13)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.9382422802850356\n",
      "Fit time:  1337.4482309818268\n"
     ]
    }
   ],
   "source": [
    "print('ACC: ', accuracy_score(y_test, gb_pred))\n",
    "print('Fit time: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gridsearch로 더 찾아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jhpark/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jhpark/Documents/ds_study/machine_learning/11. GBM, XGBoost, LGBM.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(gb_clf, param_grid\u001b[39m=\u001b[39mparams, cv\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 500],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "grid = GridSearchCV(gb_clf, param_grid=params, cv=2, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Fit time: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 시간 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf. ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]\n",
    "\n",
    "         --> y_train-1 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  17.138323068618774\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "xgb = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb.fit(X_train.values, y_train-1)\n",
    "print('Fit time: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jhpark/Documents/ds_study/machine_learning/11. GBM, XGBoost, LGBM.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy_score(y_test, grid\u001b[39m.\u001b[39;49mbest_estimator\u001b[39m.\u001b[39mpredict(X_test\u001b[39m.\u001b[39mvales))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator'"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test, xgb.predict(X_test.vales))\n",
    "# 위에 오래 걸리는 코드 실행하고 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jhpark/Documents/ds_study/machine_learning/11. GBM, XGBoost, LGBM.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m400\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m xgb\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mvalues, y_train, early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, eval_set\u001b[39m=\u001b[39;49mevals)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jhpark/Documents/ds_study/machine_learning/11.%20GBM%2C%20XGBoost%2C%20LGBM.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFit time: \u001b[39m\u001b[39m'\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ds_study/lib/python3.8/site-packages/xgboost/sklearn.py:1467\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     expected_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   1463\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1464\u001b[0m     classes\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1465\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (classes \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[1;32m   1466\u001b[0m ):\n\u001b[0;32m-> 1467\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1468\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1469\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00mclasses\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1470\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]"
     ]
    }
   ],
   "source": [
    "# 조기 종료 조건과 검증데이터\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "evals = [(X_test.values, y_test)]\n",
    "\n",
    "start_time = time.time()\n",
    "xgb = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb.fit(X_train.values, y_train, early_stopping_rounds=10, eval_set=evals)\n",
    "print('Fit time: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, xgb.best_estimator_.predict(X_test.vales))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "- 빠른 속도가 장점. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.4404\n",
      "[2]\tvalid_0's multi_logloss: 1.21574\n",
      "[3]\tvalid_0's multi_logloss: 1.04795\n",
      "[4]\tvalid_0's multi_logloss: 0.913299\n",
      "[5]\tvalid_0's multi_logloss: 0.812686\n",
      "[6]\tvalid_0's multi_logloss: 0.725964\n",
      "[7]\tvalid_0's multi_logloss: 0.652995\n",
      "[8]\tvalid_0's multi_logloss: 0.591598\n",
      "[9]\tvalid_0's multi_logloss: 0.539383\n",
      "[10]\tvalid_0's multi_logloss: 0.499944\n",
      "[11]\tvalid_0's multi_logloss: 0.462273\n",
      "[12]\tvalid_0's multi_logloss: 0.429676\n",
      "[13]\tvalid_0's multi_logloss: 0.401908\n",
      "[14]\tvalid_0's multi_logloss: 0.377718\n",
      "[15]\tvalid_0's multi_logloss: 0.357455\n",
      "[16]\tvalid_0's multi_logloss: 0.339918\n",
      "[17]\tvalid_0's multi_logloss: 0.325799\n",
      "[18]\tvalid_0's multi_logloss: 0.314716\n",
      "[19]\tvalid_0's multi_logloss: 0.301914\n",
      "[20]\tvalid_0's multi_logloss: 0.292755\n",
      "[21]\tvalid_0's multi_logloss: 0.284754\n",
      "[22]\tvalid_0's multi_logloss: 0.276745\n",
      "[23]\tvalid_0's multi_logloss: 0.270387\n",
      "[24]\tvalid_0's multi_logloss: 0.265765\n",
      "[25]\tvalid_0's multi_logloss: 0.260089\n",
      "[26]\tvalid_0's multi_logloss: 0.256178\n",
      "[27]\tvalid_0's multi_logloss: 0.251189\n",
      "[28]\tvalid_0's multi_logloss: 0.248143\n",
      "[29]\tvalid_0's multi_logloss: 0.246272\n",
      "[30]\tvalid_0's multi_logloss: 0.24341\n",
      "[31]\tvalid_0's multi_logloss: 0.241248\n",
      "[32]\tvalid_0's multi_logloss: 0.24022\n",
      "[33]\tvalid_0's multi_logloss: 0.239652\n",
      "[34]\tvalid_0's multi_logloss: 0.238179\n",
      "[35]\tvalid_0's multi_logloss: 0.23699\n",
      "[36]\tvalid_0's multi_logloss: 0.2361\n",
      "[37]\tvalid_0's multi_logloss: 0.233816\n",
      "[38]\tvalid_0's multi_logloss: 0.233106\n",
      "[39]\tvalid_0's multi_logloss: 0.233421\n",
      "[40]\tvalid_0's multi_logloss: 0.23376\n",
      "[41]\tvalid_0's multi_logloss: 0.234338\n",
      "[42]\tvalid_0's multi_logloss: 0.234543\n",
      "[43]\tvalid_0's multi_logloss: 0.234652\n",
      "[44]\tvalid_0's multi_logloss: 0.233933\n",
      "[45]\tvalid_0's multi_logloss: 0.234656\n",
      "[46]\tvalid_0's multi_logloss: 0.234617\n",
      "[47]\tvalid_0's multi_logloss: 0.235371\n",
      "[48]\tvalid_0's multi_logloss: 0.236855\n",
      "[49]\tvalid_0's multi_logloss: 0.235197\n",
      "[50]\tvalid_0's multi_logloss: 0.236224\n",
      "[51]\tvalid_0's multi_logloss: 0.236696\n",
      "[52]\tvalid_0's multi_logloss: 0.237868\n",
      "[53]\tvalid_0's multi_logloss: 0.236315\n",
      "[54]\tvalid_0's multi_logloss: 0.239717\n",
      "[55]\tvalid_0's multi_logloss: 0.241621\n",
      "[56]\tvalid_0's multi_logloss: 0.243416\n",
      "[57]\tvalid_0's multi_logloss: 0.244416\n",
      "[58]\tvalid_0's multi_logloss: 0.245904\n",
      "[59]\tvalid_0's multi_logloss: 0.244177\n",
      "[60]\tvalid_0's multi_logloss: 0.249222\n",
      "[61]\tvalid_0's multi_logloss: 0.25041\n",
      "[62]\tvalid_0's multi_logloss: 0.250982\n",
      "[63]\tvalid_0's multi_logloss: 0.249934\n",
      "[64]\tvalid_0's multi_logloss: 0.250107\n",
      "[65]\tvalid_0's multi_logloss: 0.252704\n",
      "[66]\tvalid_0's multi_logloss: 0.253061\n",
      "[67]\tvalid_0's multi_logloss: 0.25403\n",
      "[68]\tvalid_0's multi_logloss: 0.254586\n",
      "[69]\tvalid_0's multi_logloss: 0.257923\n",
      "[70]\tvalid_0's multi_logloss: 0.259529\n",
      "[71]\tvalid_0's multi_logloss: 0.259736\n",
      "[72]\tvalid_0's multi_logloss: 0.260189\n",
      "[73]\tvalid_0's multi_logloss: 0.260231\n",
      "[74]\tvalid_0's multi_logloss: 0.261524\n",
      "[75]\tvalid_0's multi_logloss: 0.261289\n",
      "[76]\tvalid_0's multi_logloss: 0.25997\n",
      "[77]\tvalid_0's multi_logloss: 0.259304\n",
      "[78]\tvalid_0's multi_logloss: 0.26109\n",
      "[79]\tvalid_0's multi_logloss: 0.264029\n",
      "[80]\tvalid_0's multi_logloss: 0.262772\n",
      "[81]\tvalid_0's multi_logloss: 0.263047\n",
      "[82]\tvalid_0's multi_logloss: 0.263413\n",
      "[83]\tvalid_0's multi_logloss: 0.264662\n",
      "[84]\tvalid_0's multi_logloss: 0.264069\n",
      "[85]\tvalid_0's multi_logloss: 0.266621\n",
      "[86]\tvalid_0's multi_logloss: 0.265539\n",
      "[87]\tvalid_0's multi_logloss: 0.265186\n",
      "[88]\tvalid_0's multi_logloss: 0.265143\n",
      "[89]\tvalid_0's multi_logloss: 0.265168\n",
      "[90]\tvalid_0's multi_logloss: 0.267091\n",
      "[91]\tvalid_0's multi_logloss: 0.26738\n",
      "[92]\tvalid_0's multi_logloss: 0.267112\n",
      "[93]\tvalid_0's multi_logloss: 0.267292\n",
      "[94]\tvalid_0's multi_logloss: 0.266334\n",
      "[95]\tvalid_0's multi_logloss: 0.266265\n",
      "[96]\tvalid_0's multi_logloss: 0.26572\n",
      "[97]\tvalid_0's multi_logloss: 0.265671\n",
      "[98]\tvalid_0's multi_logloss: 0.265732\n",
      "[99]\tvalid_0's multi_logloss: 0.265704\n",
      "[100]\tvalid_0's multi_logloss: 0.264742\n",
      "[101]\tvalid_0's multi_logloss: 0.266353\n",
      "[102]\tvalid_0's multi_logloss: 0.265204\n",
      "[103]\tvalid_0's multi_logloss: 0.265003\n",
      "[104]\tvalid_0's multi_logloss: 0.265678\n",
      "[105]\tvalid_0's multi_logloss: 0.266\n",
      "[106]\tvalid_0's multi_logloss: 0.265789\n",
      "[107]\tvalid_0's multi_logloss: 0.265048\n",
      "[108]\tvalid_0's multi_logloss: 0.265532\n",
      "[109]\tvalid_0's multi_logloss: 0.26544\n",
      "[110]\tvalid_0's multi_logloss: 0.265249\n",
      "[111]\tvalid_0's multi_logloss: 0.264829\n",
      "[112]\tvalid_0's multi_logloss: 0.265059\n",
      "[113]\tvalid_0's multi_logloss: 0.264581\n",
      "[114]\tvalid_0's multi_logloss: 0.264096\n",
      "[115]\tvalid_0's multi_logloss: 0.263705\n",
      "[116]\tvalid_0's multi_logloss: 0.264037\n",
      "[117]\tvalid_0's multi_logloss: 0.263718\n",
      "[118]\tvalid_0's multi_logloss: 0.263785\n",
      "[119]\tvalid_0's multi_logloss: 0.263835\n",
      "[120]\tvalid_0's multi_logloss: 0.263076\n",
      "[121]\tvalid_0's multi_logloss: 0.261902\n",
      "[122]\tvalid_0's multi_logloss: 0.262373\n",
      "[123]\tvalid_0's multi_logloss: 0.262332\n",
      "[124]\tvalid_0's multi_logloss: 0.26156\n",
      "[125]\tvalid_0's multi_logloss: 0.261795\n",
      "[126]\tvalid_0's multi_logloss: 0.262118\n",
      "[127]\tvalid_0's multi_logloss: 0.261702\n",
      "[128]\tvalid_0's multi_logloss: 0.261945\n",
      "[129]\tvalid_0's multi_logloss: 0.261303\n",
      "[130]\tvalid_0's multi_logloss: 0.261279\n",
      "[131]\tvalid_0's multi_logloss: 0.261045\n",
      "[132]\tvalid_0's multi_logloss: 0.261628\n",
      "[133]\tvalid_0's multi_logloss: 0.26134\n",
      "[134]\tvalid_0's multi_logloss: 0.260882\n",
      "[135]\tvalid_0's multi_logloss: 0.260979\n",
      "[136]\tvalid_0's multi_logloss: 0.260353\n",
      "[137]\tvalid_0's multi_logloss: 0.260621\n",
      "[138]\tvalid_0's multi_logloss: 0.25998\n",
      "Fit time:  7.774190187454224\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "lgbm = LGBMClassifier(n_estimators=400)\n",
    "lgbm.fit(X_train.values, y_train, early_stopping_rounds=100, eval_set=evals)\n",
    "print('Fit time: ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260264675941635"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, lgbm.predict(X_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
